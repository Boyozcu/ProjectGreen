#!/usr/bin/env python3
"""
Hybrid Segmentation System - PSPNet/PSANet ve SegFormer Entegre Sistem
Bu sistem hem klasik PSPNet/PSANet modellerini hem de modern SegFormer modelini destekler.
Ã–ÄŸrenci okul rotalarÄ±ndaki yeÅŸil alan maruziyetini analiz eder.
"""

import os
import logging
import argparse
import sys
import cv2
import numpy as np
import torch
import torch.backends.cudnn as cudnn
import torch.nn.functional as F
import pandas as pd
from datetime import datetime
from PIL import Image, ImageDraw, ImageFont, ImageEnhance
import requests
import matplotlib.pyplot as plt
import seaborn as sns
import json
from io import BytesIO
import time
import warnings
from sklearn.cluster import KMeans
import openpyxl
from pathlib import Path

# SegFormer imports
from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation

# Disable warnings
warnings.filterwarnings('ignore')
cv2.ocl.setUseOpenCL(False)

# Path configurations
GRAY_PATH = '/n/data2/hms/dbmi/patel/beacon/europe/segs/'
IMGS_PATH = '/n/data2/hms/dbmi/patel/beacon/europe/euimages/'
CHUNK_PATH = '/n/data2/hms/dbmi/patel/beacon/europe/metadata/'
CHUNK_PATH_SEG = '/n/data2/hms/dbmi/patel/beacon/europe/metadata/eu_meta_seg/'

class HybridSegmentationSystem:
    """Hibrit segmentasyon sistemi - PSPNet/PSANet ve SegFormer modellerini destekler"""
    3 
    def __init__(self, model_type='segformer', api_key=None, config_path=None):
        """
        Initialize hybrid system
        
        Args:
            model_type: 'segformer', 'pspnet', or 'psanet'
            api_key: Google Street View API key (SegFormer iÃ§in)
            config_path: PSPNet/PSANet config path
        """
        self.model_type = model_type
        self.api_key = api_key
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.logger = self.get_logger()
        
        # Gece fotoÄŸrafÄ± tespit parametreleri
        self.night_detection_threshold = 50
        self.blue_dominance_threshold = 1.2
        
        self.setup_directories()
        
        if model_type == 'segformer':
            self.load_segformer_model()
        else:
            if config_path is None:
                raise ValueError("Config path required for PSPNet/PSANet models")
            self.load_classic_model(config_path)
    
    def get_logger(self):
        """Logger oluÅŸtur"""
        logger_name = "hybrid-segmentation"
        logger = logging.getLogger(logger_name)
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            fmt = "[%(asctime)s %(levelname)s %(filename)s line %(lineno)d %(process)d] %(message)s"
            handler.setFormatter(logging.Formatter(fmt))
            logger.addHandler(handler)
        
        return logger
    
    def setup_directories(self):
        """Gerekli klasÃ¶rleri oluÅŸtur"""
        self.directories = {
            'images': 'street_view_images',
            'analysis': 'analysis_results',
            'visualizations': 'visualizations',
            'reports': 'reports',
            'masks': 'vegetation_masks',
            'segmentation_output': 'segmentation_output'
        }
        
        for dir_path in self.directories.values():
            os.makedirs(dir_path, exist_ok=True)
    
    def load_segformer_model(self):
        """SegFormer modelini yÃ¼kle"""
        self.logger.info("ğŸ¤– SegFormer modeli yÃ¼kleniyor...")
        try:
            self.feature_extractor = SegformerFeatureExtractor.from_pretrained(
                "nvidia/segformer-b5-finetuned-cityscapes-1024-1024"
            )
            self.model = SegformerForSemanticSegmentation.from_pretrained(
                "nvidia/segformer-b5-finetuned-cityscapes-1024-1024"
            )
            self.model.to(self.device)
            self.model.eval()
            self.logger.info(f"âœ… SegFormer model yÃ¼klendi ({self.device})")
        except Exception as e:
            self.logger.error(f"âŒ SegFormer model yÃ¼kleme hatasÄ±: {e}")
            raise
    
    def load_classic_model(self, config_path):
        """PSPNet/PSANet modelini yÃ¼kle"""
        self.args = self.load_config(config_path)
        self.check_config(self.args)
        
        os.environ["CUDA_VISIBLE_DEVICES"] = ','.join(str(x) for x in self.args.test_gpu)
        
        self.logger.info(self.args)
        self.logger.info("=> Creating classic model ...")
        self.logger.info("Classes: {}".format(self.args.classes))
        
        # Model parametreleri
        self.value_scale = 255
        self.mean = [0.485, 0.456, 0.406]
        self.mean = [item * self.value_scale for item in self.mean]
        self.std = [0.229, 0.224, 0.225]
        self.std = [item * self.value_scale for item in self.std]
        self.colors = np.loadtxt(self.args.colors_path).astype('uint8')
        
        # Model yÃ¼kleme
        if self.args.arch == 'psp':
            from model.pspnet import PSPNet
            model = PSPNet(layers=self.args.layers, classes=self.args.classes, 
                          zoom_factor=self.args.zoom_factor, pretrained=False)
        elif self.args.arch == 'psa':
            from model.psanet import PSANet
            model = PSANet(layers=self.args.layers, classes=self.args.classes, 
                          zoom_factor=self.args.zoom_factor, compact=self.args.compact,
                          shrink_factor=self.args.shrink_factor, mask_h=self.args.mask_h, 
                          mask_w=self.args.mask_w, normalization_factor=self.args.normalization_factor, 
                          psa_softmax=self.args.psa_softmax, pretrained=False)
        
        self.model = torch.nn.DataParallel(model)
        cudnn.benchmark = False
        
        if os.path.isfile(self.args.model_path):
            self.logger.info("=> Loading checkpoint '{}'".format(self.args.model_path))
            checkpoint = torch.load(self.args.model_path, map_location=torch.device('cpu'))
            self.model.load_state_dict(checkpoint['state_dict'], strict=False)
            self.logger.info("=> Loaded checkpoint '{}'".format(self.args.model_path))
        else:
            raise RuntimeError("=> No checkpoint found at '{}'".format(self.args.model_path))
    
    def load_config(self, config_path):
        """Config dosyasÄ±nÄ± yÃ¼kle"""
        # Bu fonksiyon config dosyasÄ±ndan parametreleri yÃ¼kler
        # Basit bir implementasyon - gerÃ§ek config dosyanÄ±zÄ± kullanÄ±n
        class Args:
            def __init__(self):
                # VarsayÄ±lan deÄŸerler - config dosyanÄ±zdan yÃ¼kleyin
                self.arch = 'psp'  # or 'psa'
                self.layers = 50
                self.classes = 150
                self.zoom_factor = 8
                self.test_gpu = [0]
                self.model_path = 'path/to/your/model.pth'
                self.colors_path = 'config/cityscapes_colors.txt'
                self.base_size = 2048
                self.test_h = 713
                self.test_w = 713
                self.scales = [1.0]
                # PSANet specific
                self.compact = False
                self.shrink_factor = 2
                self.mask_h = None
                self.mask_w = None
                self.normalization_factor = 1.0
                self.psa_softmax = True
        
        return Args()
    
    def check_config(self, args):
        """Config parametrelerini kontrol et"""
        assert args.classes > 1
        assert args.zoom_factor in [1, 2, 4, 8]
        
        if args.arch == 'psp':
            assert (args.test_h - 1) % 8 == 0 and (args.test_w - 1) % 8 == 0
        elif args.arch == 'psa':
            if args.compact:
                args.mask_h = (args.test_h - 1) // (8 * args.shrink_factor) + 1
                args.mask_w = (args.test_w - 1) // (8 * args.shrink_factor) + 1
            else:
                assert (args.mask_h is None and args.mask_w is None) or (args.mask_h is not None and args.mask_w is not None)
                if args.mask_h is None and args.mask_w is None:
                    args.mask_h = 2 * ((args.test_h - 1) // (8 * args.shrink_factor) + 1) - 1
                    args.mask_w = 2 * ((args.test_w - 1) // (8 * args.shrink_factor) + 1) - 1
    
    def download_street_view_image(self, coords, angle, location_id, size="640x640", fov=90, reject_night=True):
        """Street View gÃ¶rÃ¼ntÃ¼sÃ¼ indir"""
        if not self.api_key:
            self.logger.error("API key gerekli")
            return None, None
            
        url = f"https://maps.googleapis.com/maps/api/streetview"
        params = {
            'size': size,
            'location': coords,
            'fov': fov,
            'heading': angle,
            'pitch': 0,
            'key': self.api_key
        }
        
        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            if len(response.content) > 1000:
                image = Image.open(BytesIO(response.content)).convert("RGB")
                
                if reject_night:
                    location_info = f"Lokasyon {location_id}, AÃ§Ä± {angle}Â°"
                    is_acceptable, night_info = self.filter_daylight_images(image, location_info)
                    
                    if not is_acceptable:
                        return None, night_info
                
                # GÃ¶rÃ¼ntÃ¼ kalitesini artÄ±r
                enhancer = ImageEnhance.Contrast(image)
                image = enhancer.enhance(1.2)
                
                enhancer = ImageEnhance.Sharpness(image)
                image = enhancer.enhance(1.1)
                
                return image, None
        except Exception as e:
            self.logger.error(f"âš ï¸ GÃ¶rÃ¼ntÃ¼ indirme hatasÄ±: {e}")
        
        return None, None
    
    def filter_daylight_images(self, image, location_info=""):
        """Gece fotoÄŸraflarÄ±nÄ± filtrele"""
        try:
            img_array = np.array(image)
            
            # 1. Ortalama parlaklÄ±k kontrolÃ¼
            avg_brightness = np.mean(img_array)
            
            # 2. RGB kanallarÄ±nÄ±n daÄŸÄ±lÄ±mÄ±
            r_mean = np.mean(img_array[:, :, 0])
            g_mean = np.mean(img_array[:, :, 1])
            b_mean = np.mean(img_array[:, :, 2])
            
            # 3. Mavi baskÄ±nlÄ±k oranÄ± (gece gÃ¶rÃ¼ntÃ¼lerinde mavi ton artar)
            blue_dominance = b_mean / (r_mean + 1e-6)
            
            # 4. Kontrast analizi
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            contrast = np.std(gray)
            
            # Karar verme
            is_night = (avg_brightness < self.night_detection_threshold or 
                       blue_dominance > self.blue_dominance_threshold or
                       contrast < 20)
            
            night_info = {
                'location': location_info,
                'avg_brightness': float(avg_brightness),
                'blue_dominance': float(blue_dominance),
                'contrast': float(contrast),
                'is_night': is_night,
                'reject_reason': []
            }
            
            if avg_brightness < self.night_detection_threshold:
                night_info['reject_reason'].append(f"DÃ¼ÅŸÃ¼k parlaklÄ±k ({avg_brightness:.1f} < {self.night_detection_threshold})")
            
            if blue_dominance > self.blue_dominance_threshold:
                night_info['reject_reason'].append(f"Mavi baskÄ±nlÄ±k ({blue_dominance:.2f} > {self.blue_dominance_threshold})")
            
            if contrast < 20:
                night_info['reject_reason'].append(f"DÃ¼ÅŸÃ¼k kontrast ({contrast:.1f} < 20)")
            
            return not is_night, night_info
            
        except Exception as e:
            self.logger.error(f"Gece tespit hatasÄ±: {e}")
            return True, {'error': str(e)}
    
    def analyze_image_segformer(self, image):
        """SegFormer ile gÃ¶rÃ¼ntÃ¼ analizi"""
        try:
            inputs = self.feature_extractor(images=image, return_tensors="pt").to(self.device)
            
            with torch.no_grad():
                outputs = self.model(**inputs)
            
            logits = outputs.logits
            predicted_map = torch.nn.functional.interpolate(
                logits,
                size=image.size[::-1],
                mode="bilinear",
                align_corners=False
            ).argmax(dim=1).squeeze().cpu().numpy()
            
            # Cityscapes sÄ±nÄ±flarÄ±
            classes = {
                'vegetation': 8,  # Bitki Ã¶rtÃ¼sÃ¼
                'sky': 10,       # GÃ¶kyÃ¼zÃ¼
                'building': 2,   # Binalar
                'road': 0,       # Yol
                'sidewalk': 1,   # KaldÄ±rÄ±m
                'car': 13,       # Arabalar
                'person': 11,    # Ä°nsanlar
                'pole': 5,       # Direkler
                'fence': 4       # Ã‡itler
            }
            
            analysis = {}
            total_pixels = predicted_map.size
            
            for class_name, class_id in classes.items():
                mask = (predicted_map == class_id)
                pixel_count = np.sum(mask)
                percentage = (pixel_count / total_pixels) * 100
                analysis[class_name] = {
                    'pixels': int(pixel_count),
                    'percentage': float(percentage),
                    'mask': mask
                }
            
            # YeÅŸil alan detaylarÄ±
            vegetation_mask = analysis['vegetation']['mask']
            mask_uint8 = (vegetation_mask * 255).astype(np.uint8)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            green_regions = []
            for i, contour in enumerate(contours):
                area = cv2.contourArea(contour)
                if area > 50:
                    x, y, w, h = cv2.boundingRect(contour)
                    green_regions.append({
                        'id': i,
                        'area': float(area),
                        'bbox': (int(x), int(y), int(w), int(h)),
                        'center': (int(x + w/2), int(y + h/2)),
                        'aspect_ratio': float(w/h) if h > 0 else 0
                    })
            
            analysis['green_regions'] = sorted(green_regions, key=lambda x: x['area'], reverse=True)
            analysis['num_green_regions'] = len(green_regions)
            analysis['largest_green_area'] = green_regions[0]['area'] if green_regions else 0
            
            # GVI hesaplama
            gvi = analysis['vegetation']['percentage']
            analysis['gvi'] = gvi
            
            # Bellek temizleme
            del inputs, outputs, logits, predicted_map
            if self.device == "cuda":
                torch.cuda.empty_cache()
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"âŒ SegFormer analiz hatasÄ±: {e}")
            return None
    
    def analyze_image_classic(self, image_path, gray_path):
        """PSPNet/PSANet ile gÃ¶rÃ¼ntÃ¼ analizi"""
        try:
            image = cv2.imread(image_path, cv2.IMREAD_COLOR)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            h, w, _ = image.shape
            
            prediction = np.zeros((h, w, self.args.classes), dtype=float)
            
            for scale in self.args.scales:
                long_size = round(scale * self.args.base_size)
                new_h = long_size
                new_w = long_size
                if h > w:
                    new_w = round(long_size/float(h)*w)
                else:
                    new_h = round(long_size/float(w)*h)
                
                image_scale = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                prediction += self.scale_process(self.model.eval(), image_scale, self.args.classes, 
                                               self.args.test_h, self.args.test_w, h, w, self.mean, self.std)
            
            prediction = np.argmax(prediction, axis=2)
            gray = np.uint8(prediction)
            
            # SÄ±nÄ±f yÃ¼zdelerini hesapla
            perclist = []
            for i in range(self.args.classes):
                perc = np.sum(prediction == i) / (prediction.shape[1] * prediction.shape[0])
                perclist.append(perc)
            
            # Gray image kaydet
            cv2.imwrite(gray_path, gray)
            self.logger.info("=> Prediction saved in {}".format(gray_path))
            
            return perclist
            
        except Exception as e:
            self.logger.error(f"âŒ Classic model analiz hatasÄ±: {e}")
            return None
    
    def net_process(self, model, image, mean, std=None, flip=True):
        """Network processing for classic models"""
        input = torch.from_numpy(image.transpose((2, 0, 1))).float()
        if std is None:
            for t, m in zip(input, mean):
                t.sub_(m)
        else:
            for t, m, s in zip(input, mean, std):
                t.sub_(m).div_(s)
        
        input = input.unsqueeze(0)
        if flip:
            input = torch.cat([input, input.flip(3)], 0)
        
        with torch.no_grad():
            output = model(input)
        
        _, _, h_i, w_i = input.shape
        _, _, h_o, w_o = output.shape
        
        if (h_o != h_i) or (w_o != w_i):
            output = F.interpolate(output, (h_i, w_i), mode='bilinear', align_corners=True)
        
        output = F.softmax(output, dim=1)
        
        if flip:
            output = (output[0] + output[1].flip(2)) / 2
        else:
            output = output[0]
        
        output = output.data.cpu().numpy()
        output = output.transpose(1, 2, 0)
        return output
    
    def scale_process(self, model, image, classes, crop_h, crop_w, h, w, mean, std=None, stride_rate=2/3):
        """Scale processing for classic models"""
        ori_h, ori_w, _ = image.shape
        pad_h = max(crop_h - ori_h, 0)
        pad_w = max(crop_w - ori_w, 0)
        pad_h_half = int(pad_h / 2)
        pad_w_half = int(pad_w / 2)
        
        if pad_h > 0 or pad_w > 0:
            image = cv2.copyMakeBorder(image, pad_h_half, pad_h - pad_h_half, 
                                     pad_w_half, pad_w - pad_w_half, 
                                     cv2.BORDER_CONSTANT, value=mean)
        
        new_h, new_w, _ = image.shape
        stride_h = int(np.ceil(crop_h * stride_rate))
        stride_w = int(np.ceil(crop_w * stride_rate))
        grid_h = int(np.ceil(float(new_h - crop_h) / stride_h) + 1)
        grid_w = int(np.ceil(float(new_w - crop_w) / stride_w) + 1)
        
        prediction_crop = np.zeros((new_h, new_w, classes), dtype=float)
        count_crop = np.zeros((new_h, new_w), dtype=float)
        
        for index_h in range(0, grid_h):
            for index_w in range(0, grid_w):
                s_h = index_h * stride_h
                e_h = min(s_h + crop_h, new_h)
                s_h = e_h - crop_h
                s_w = index_w * stride_w
                e_w = min(s_w + crop_w, new_w)
                s_w = e_w - crop_w
                
                image_crop = image[s_h:e_h, s_w:e_w].copy()
                count_crop[s_h:e_h, s_w:e_w] += 1
                prediction_crop[s_h:e_h, s_w:e_w, :] += self.net_process(model, image_crop, mean, std)
        
        prediction_crop /= np.expand_dims(count_crop, 2)
        prediction_crop = prediction_crop[pad_h_half:pad_h_half+ori_h, pad_w_half:pad_w_half+ori_w]
        prediction = cv2.resize(prediction_crop, (w, h), interpolation=cv2.INTER_LINEAR)
        return prediction
    
    def create_visualization(self, image, analysis, save_path=None):
        """GÃ¶rselleÅŸtirme oluÅŸtur"""
        if self.model_type == 'segformer':
            return self.create_segformer_visualization(image, analysis, save_path)
        else:
            return self.create_classic_visualization(image, analysis, save_path)
    
    def create_segformer_visualization(self, image, analysis, save_path=None):
        """SegFormer iÃ§in gÃ¶rselleÅŸtirme"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('SegFormer - DetaylÄ± YeÅŸil Alan Analizi', fontsize=16, fontweight='bold')
        
        # 1. Orijinal gÃ¶rÃ¼ntÃ¼
        axes[0, 0].imshow(image)
        axes[0, 0].set_title('Orijinal GÃ¶rÃ¼ntÃ¼')
        axes[0, 0].axis('off')
        
        # 2. YeÅŸil alanlar overlay
        img_array = np.array(image)
        overlay = np.zeros_like(img_array)
        if analysis and 'vegetation' in analysis:
            vegetation_mask = analysis['vegetation']['mask']
            overlay[vegetation_mask] = [0, 255, 0]  # YeÅŸil renk
            
            combined = cv2.addWeighted(img_array, 0.7, overlay, 0.3, 0)
            axes[0, 1].imshow(combined)
            axes[0, 1].set_title(f'YeÅŸil Alanlar (GVI: {analysis["gvi"]:.1f}%)')
            axes[0, 1].axis('off')
        
        # 3. SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±
        if analysis:
            class_names = []
            percentages = []
            colors = []
            
            class_colors = {
                'vegetation': '#228B22', 'sky': '#87CEEB', 'building': '#8B4513',
                'road': '#696969', 'sidewalk': '#D3D3D3', 'car': '#FF4500',
                'person': '#FFB6C1', 'pole': '#2F4F4F', 'fence': '#DEB887'
            }
            
            for class_name in ['vegetation', 'building', 'road', 'sky', 'sidewalk']:
                if class_name in analysis and analysis[class_name]['percentage'] > 0.5:
                    class_names.append(class_name.title())
                    percentages.append(analysis[class_name]['percentage'])
                    colors.append(class_colors.get(class_name, '#808080'))
            
            if class_names:
                axes[0, 2].pie(percentages, labels=class_names, colors=colors, autopct='%1.1f%%')
                axes[0, 2].set_title('SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±')
        
        # 4. YeÅŸil bÃ¶lge analizi
        if analysis and analysis.get('green_regions'):
            img_regions = img_array.copy()
            for i, region in enumerate(analysis['green_regions'][:5]):  # Ä°lk 5 bÃ¶lge
                x, y, w, h = region['bbox']
                cv2.rectangle(img_regions, (x, y), (x+w, y+h), (255, 0, 0), 2)
                cv2.putText(img_regions, f"{i+1}", (x, y-5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
            
            axes[1, 0].imshow(img_regions)
            axes[1, 0].set_title(f'YeÅŸil BÃ¶lgeler ({analysis["num_green_regions"]} adet)')
            axes[1, 0].axis('off')
        
        # 5. Ä°statistikler
        axes[1, 1].axis('off')
        if analysis:
            stats_text = f"""
            ğŸ“Š YEÅIL ALAN ANALÄ°ZÄ°
            
            ğŸŒ¿ GVI Skoru: {analysis.get('gvi', 0):.1f}%
            
            ğŸŒ³ YeÅŸil BÃ¶lge SayÄ±sÄ±: {analysis.get('num_green_regions', 0)}
            
            ğŸ“ En BÃ¼yÃ¼k YeÅŸil Alan: {analysis.get('largest_green_area', 0):.0f} piksel
            
            ğŸ¢ Bina OranÄ±: {analysis.get('building', {}).get('percentage', 0):.1f}%
            
            ğŸ›£ï¸ Yol OranÄ±: {analysis.get('road', {}).get('percentage', 0):.1f}%
            
            â˜ï¸ GÃ¶kyÃ¼zÃ¼ OranÄ±: {analysis.get('sky', {}).get('percentage', 0):.1f}%
            """
            axes[1, 1].text(0.1, 0.9, stats_text, transform=axes[1, 1].transAxes, 
                           fontsize=12, verticalalignment='top', fontfamily='monospace')
        
        # 6. Renk analizi
        if analysis:
            img_hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
            green_pixels = img_hsv[analysis['vegetation']['mask']]
            
            if len(green_pixels) > 0:
                axes[1, 2].scatter(green_pixels[:, 0], green_pixels[:, 1], 
                                 c=green_pixels[:, 2], cmap='viridis', alpha=0.6, s=1)
                axes[1, 2].set_xlabel('Hue')
                axes[1, 2].set_ylabel('Saturation')
                axes[1, 2].set_title('YeÅŸil Piksel DaÄŸÄ±lÄ±mÄ± (HSV)')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            self.logger.info(f"GÃ¶rselleÅŸtirme kaydedildi: {save_path}")
        
        return fig
    
    def create_classic_visualization(self, image_path, analysis, save_path=None):
        """Classic model iÃ§in gÃ¶rselleÅŸtirme"""
        # Bu fonksiyon classic model Ã§Ä±ktÄ±larÄ± iÃ§in gÃ¶rselleÅŸtirme yapar
        # Implementasyon gerektiÄŸinde eklenebilir
        pass
    
    def analyze_location(self, location, reject_night=True):
        """Lokasyon analizi - her iki model tÃ¼rÃ¼ iÃ§in"""
        if self.model_type == 'segformer':
            return self.analyze_location_segformer(location, reject_night)
        else:
            return self.analyze_location_classic(location)
    
    def analyze_location_segformer(self, location, reject_night=True):
        """SegFormer ile lokasyon analizi"""
        self.logger.info(f"ğŸ“ Lokasyon: {location['name']} - {location['coords']}")
        
        angles = [0, 90, 180, 270]  # 4 yÃ¶n
        results = {}
        rejected_images = []
        total_gvi = 0
        valid_images = 0
        
        for angle in angles:
            self.logger.info(f"  ğŸ“¸ {angle}Â° aÃ§Ä±sÄ±ndan gÃ¶rÃ¼ntÃ¼ indiriliyor...")
            
            image, night_info = self.download_street_view_image(
                location['coords'], angle, location['id'], reject_night=reject_night
            )
            
            if image is None:
                if night_info:
                    rejected_images.append({
                        'angle': angle,
                        'reason': 'night_detection',
                        'details': night_info
                    })
                    self.logger.info(f"  ğŸŒ™ {angle}Â° - Gece fotoÄŸrafÄ± reddedildi")
                else:
                    self.logger.info(f"  âŒ {angle}Â° - GÃ¶rÃ¼ntÃ¼ indirilemedi")
                
                results[angle] = {
                    'image_available': False,
                    'gvi': 0,
                    'error': night_info or 'Download failed'
                }
                continue
            
            # GÃ¶rÃ¼ntÃ¼yÃ¼ kaydet
            image_filename = f"{location['id']}_{angle}.jpg"
            image_path = os.path.join(self.directories['images'], image_filename)
            image.save(image_path, quality=95)
            
            # Analiz et
            analysis = self.analyze_image_segformer(image)
            
            if analysis:
                gvi = analysis.get('gvi', 0)
                total_gvi += gvi
                valid_images += 1
                
                self.logger.info(f"  âœ… {angle}Â° - GVI: {gvi:.1f}%")
                
                # GÃ¶rselleÅŸtirme oluÅŸtur
                viz_filename = f"{location['id']}_{angle}_analysis.png"
                viz_path = os.path.join(self.directories['visualizations'], viz_filename)
                self.create_visualization(image, analysis, viz_path)
                
                results[angle] = {
                    'image_available': True,
                    'gvi': gvi,
                    'analysis': analysis,
                    'image_path': image_path,
                    'viz_path': viz_path
                }
            else:
                self.logger.info(f"  âŒ {angle}Â° - Analiz baÅŸarÄ±sÄ±z")
                results[angle] = {
                    'image_available': True,
                    'gvi': 0,
                    'error': 'Analysis failed'
                }
        
        # Lokasyon Ã¶zeti
        avg_gvi = total_gvi / valid_images if valid_images > 0 else 0
        
        summary = {
            'location_id': location['id'],
            'location_name': location['name'],
            'coordinates': location['coords'],
            'total_images': len(angles),
            'valid_images': valid_images,
            'rejected_images': len(rejected_images),
            'average_gvi': avg_gvi,
            'analysis_timestamp': datetime.now().isoformat()
        }
        
        self.logger.info(f"  ğŸ“Š Ortalama GVI: {avg_gvi:.1f}% ({valid_images}/{len(angles)} gÃ¶rÃ¼ntÃ¼)")
        
        return {
            'location_info': summary,
            'angles': results,
            'rejected_images': rejected_images,
            'summary': summary
        }
    
    def analyze_location_classic(self, location):
        """Classic model ile lokasyon analizi"""
        # Bu fonksiyon batch processing iÃ§in tasarlanmÄ±ÅŸ
        # Metadata CSV dosyasÄ±ndan lokasyonlarÄ± okur
        pass
    
    def process_batch_classic(self, chunk_code):
        """Classic model iÃ§in batch processing"""
        if os.path.exists(CHUNK_PATH_SEG + f'{chunk_code}_seg.csv'):
            self.logger.info('Bu chunk iÃ§in segmentasyon zaten tamamlanmÄ±ÅŸ.')
            return
        
        start = datetime.now()
        
        # Metadata yÃ¼kle
        if os.path.exists(CHUNK_PATH_SEG + f'{chunk_code}_seg_m.csv'):
            metadf = pd.read_csv(CHUNK_PATH_SEG + f'{chunk_code}_seg_m.csv')
        else:
            metadf = pd.read_csv(CHUNK_PATH + f'meta_lau_split_500_{chunk_code}.csv')
            metadf['segmented'] = 0
            new_columns = pd.DataFrame(0, index=metadf.index, columns=[f'c{nclass}' for nclass in range(1, 151)])
            metadf = pd.concat([metadf, new_columns], axis=1)
        
        # Her satÄ±r iÃ§in iÅŸlem yap
        for index, row in metadf.iterrows():
            if row['segmented'] == 0:
                # GÃ¶rÃ¼ntÃ¼ yollarÄ±nÄ± oluÅŸtur
                COUNTRYPATH = os.path.join(IMGS_PATH, str(row['country']))
                SUBPATH = os.path.join(COUNTRYPATH, str(row['lau_code']))
                imageid = str(row['lau_code']) + '_' + str(int(row['grid_id'])).zfill(6) + '_' + str(int(row['gsv_year']))[-2:]
                
                # Segmentasyon Ã§Ä±ktÄ± klasÃ¶rlerini oluÅŸtur
                COUNTRYPATH_SEG = os.path.join(GRAY_PATH, str(row['country']))
                if not os.path.exists(COUNTRYPATH_SEG):
                    os.mkdir(COUNTRYPATH_SEG)
                SUBPATH_SEG = os.path.join(COUNTRYPATH_SEG, str(row['lau_code']))
                if not os.path.exists(SUBPATH_SEG):
                    os.mkdir(SUBPATH_SEG)
                
                plist = np.zeros(shape=(4, 150))
                flag_img = 0
                
                # 4 yÃ¶n iÃ§in iÅŸlem yap
                for head, hid in zip([0, 1, 2, 3], ['N', 'E', 'S', 'W']):
                    img_path = os.path.join(SUBPATH, str(imageid) + str(hid) + '.png')
                    gray_path = os.path.join(SUBPATH_SEG, str(imageid) + str(hid) + '_seg.png')
                    
                    try:
                        plist_ = self.analyze_image_classic(img_path, gray_path)
                        if plist_ is not None:
                            plist[head] = plist_
                        else:
                            flag_img = 1
                    except Exception as e:
                        self.logger.error(f"GÃ¶rÃ¼ntÃ¼ iÅŸleme hatasÄ± {img_path}: {e}")
                        flag_img = 1
                
                # SonuÃ§larÄ± kaydet
                if flag_img == 0:
                    metadf.loc[index, 'segmented'] = 1
                    metadf.iloc[index, 12:162] = list(np.mean(plist, axis=0))
                else:
                    metadf.loc[index, 'segmented'] = 0
                    metadf.iloc[index, 12:162] = 0
                
                # Ara kayÄ±t
                if index % 100 == 0:
                    metadf.to_csv(CHUNK_PATH_SEG + f'{chunk_code}_seg_m.csv', index=False)
        
        # Final kayÄ±t
        metadf.to_csv(CHUNK_PATH_SEG + f'{chunk_code}_seg.csv', index=False)
        if os.path.exists(CHUNK_PATH_SEG + f'{chunk_code}_seg_m.csv'):
            os.remove(CHUNK_PATH_SEG + f'{chunk_code}_seg_m.csv')
        
        end = datetime.now()
        self.logger.info(f"Toplam iÅŸlem sÃ¼resi {len(metadf)} gÃ¶rÃ¼ntÃ¼ iÃ§in: {end - start}")
    
    def create_comprehensive_report(self, results):
        """KapsamlÄ± rapor oluÅŸtur"""
        if not results:
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # CSV raporu
        csv_path = os.path.join(self.directories['reports'], f'green_analysis_report_{timestamp}.csv')
        
        csv_data = []
        for result in results:
            location_info = result['location_info']
            for angle, angle_data in result['angles'].items():
                csv_data.append({
                    'location_id': location_info['location_id'],
                    'location_name': location_info['location_name'],
                    'coordinates': location_info['coordinates'],
                    'angle': angle,
                    'gvi': angle_data.get('gvi', 0),
                    'image_available': angle_data.get('image_available', False),
                    'analysis_timestamp': location_info['analysis_timestamp']
                })
        
        pd.DataFrame(csv_data).to_csv(csv_path, index=False)
        self.logger.info(f"CSV raporu kaydedildi: {csv_path}")
    
    def load_student_routes(self, excel_path):
        """Excel dosyasÄ±ndan Ã¶ÄŸrenci rotalarÄ±nÄ± yÃ¼kle"""
        try:
            df = pd.read_excel(excel_path)
            self.logger.info(f"ğŸ“Š Excel dosyasÄ± yÃ¼klendi: {len(df)} koordinat noktasÄ±")
            
            # Veriyi student kodlarÄ±na gÃ¶re grupla
            routes = {}
            for code in df['code'].unique():
                student_data = df[df['code'] == code].sort_values('point_id')
                routes[code] = {
                    'coordinates': [],
                    'point_count': len(student_data)
                }
                
                for _, row in student_data.iterrows():
                    # x = longitude, y = latitude formatÄ±nda
                    coord = f"{row['y']},{row['x']}"  # lat,lng format
                    routes[code]['coordinates'].append({
                        'point_id': row['point_id'],
                        'coords': coord,
                        'lat': row['y'],
                        'lng': row['x']
                    })
            
            self.logger.info(f"ğŸ’ {len(routes)} Ã¶ÄŸrenci rotasÄ± yÃ¼klendi")
            for code, route in routes.items():
                self.logger.info(f"   {code}: {route['point_count']} koordinat noktasÄ±")
            
            return routes
            
        except Exception as e:
            self.logger.error(f"âŒ Excel dosyasÄ± yÃ¼kleme hatasÄ±: {e}")
            return None
    
    def calculate_route_green_exposure(self, route_data, student_code, angles_per_point=4):
        """Ã–ÄŸrenci rotasÄ±nÄ±n yeÅŸil alan maruziyetini hesapla"""
        self.logger.info(f"ğŸ’ {student_code} rotasÄ± analiz ediliyor...")
        
        coordinates = route_data['coordinates']
        total_gvi = 0
        valid_points = 0
        point_analyses = []
        rejected_images_total = 0
        
        for i, point in enumerate(coordinates, 1):
            self.logger.info(f"  ğŸ“ Nokta {point['point_id']}: {point['coords']}")
            
            # Her koordinat noktasÄ± iÃ§in bir lokasyon objesi oluÅŸtur
            location = {
                'id': f"{student_code}_point_{point['point_id']}",
                'name': f"{student_code} - Nokta {point['point_id']}",
                'coords': point['coords']
            }
            
            # Bu nokta iÃ§in yeÅŸil alan analizi yap
            point_result = self.analyze_location_segformer(location, reject_night=True)
            
            if point_result['summary']['valid_images'] > 0:
                point_gvi = point_result['summary']['average_gvi']
                total_gvi += point_gvi
                valid_points += 1
                
                self.logger.info(f"    âœ… Nokta {point['point_id']} GVI: {point_gvi:.1f}%")
            else:
                self.logger.info(f"    âŒ Nokta {point['point_id']}: GeÃ§erli gÃ¶rÃ¼ntÃ¼ yok")
            
            point_analyses.append(point_result)
            rejected_images_total += len(point_result.get('rejected_images', []))
        
        # Rota Ã¶zeti
        average_route_gvi = total_gvi / valid_points if valid_points > 0 else 0
        
        route_summary = {
            'student_code': student_code,
            'total_points': len(coordinates),
            'analyzed_points': len(point_analyses),
            'valid_points': valid_points,
            'average_route_gvi': average_route_gvi,
            'total_gvi': total_gvi,
            'rejected_images_count': rejected_images_total,
            'analysis_timestamp': datetime.now().isoformat(),
            'route_length_km': self.calculate_route_distance(coordinates)
        }
        
        self.logger.info(f"ğŸ¯ {student_code} rota Ã¶zeti:")
        self.logger.info(f"   ğŸ“Š Ortalama GVI: {average_route_gvi:.1f}%")
        self.logger.info(f"   ğŸ“ Rota uzunluÄŸu: {route_summary['route_length_km']:.2f} km")
        self.logger.info(f"   âœ… GeÃ§erli nokta: {valid_points}/{len(coordinates)}")
        
        return {
            'summary': route_summary,
            'point_analyses': point_analyses
        }
    
    def calculate_route_distance(self, coordinates):
        """Rota koordinatlarÄ± arasÄ±ndaki mesafeyi hesapla (Haversine formula)"""
        def haversine(lat1, lon1, lat2, lon2):
            R = 6371  # DÃ¼nya yarÄ±Ã§apÄ± (km)
            
            lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
            dlat = lat2 - lat1
            dlon = lat2 - lon1
            
            a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
            c = 2 * np.arcsin(np.sqrt(a))
            
            return R * c
        
        total_distance = 0
        for i in range(len(coordinates) - 1):
            lat1, lng1 = coordinates[i]['lat'], coordinates[i]['lng']
            lat2, lng2 = coordinates[i+1]['lat'], coordinates[i+1]['lng']
            
            distance = haversine(lat1, lng1, lat2, lng2)
            total_distance += distance
        
        return total_distance
    
    def analyze_all_student_routes(self, excel_path):
        """TÃ¼m Ã¶ÄŸrenci rotalarÄ±nÄ± analiz et"""
        # Excel dosyasÄ±ndan rotalarÄ± yÃ¼kle
        routes = self.load_student_routes(excel_path)
        if not routes:
            return None
        
        all_results = []
        
        # Her Ã¶ÄŸrenci rotasÄ±nÄ± analiz et
        for student_code, route_data in routes.items():
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"ğŸ’ {student_code} Ã¶ÄŸrencisinin rotasÄ± analiz ediliyor...")
            
            route_result = self.calculate_route_green_exposure(route_data, student_code)
            all_results.append(route_result)
        
        # KarÅŸÄ±laÅŸtÄ±rmalÄ± rapor oluÅŸtur
        self.create_student_comparison_report(all_results)
        
        return all_results
    
    def create_student_comparison_report(self, all_results):
        """Ã–ÄŸrenciler arasÄ± karÅŸÄ±laÅŸtÄ±rmalÄ± rapor oluÅŸtur"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. CSV raporu - Ã–ÄŸrenci Ã¶zetleri
        summary_data = []
        for result in all_results:
            summary = result['summary']
            summary_data.append({
                'Ã–ÄŸrenci_Kodu': summary['student_code'],
                'Toplam_Nokta': summary['total_points'],
                'GeÃ§erli_Nokta': summary['valid_points'],
                'Ortalama_GVI_%': round(summary['average_route_gvi'], 2),
                'Toplam_GVI': round(summary['total_gvi'], 2),
                'Rota_Uzunluk_km': round(summary['route_length_km'], 3),
                'GVI_per_km': round(summary['average_route_gvi'] / summary['route_length_km'] if summary['route_length_km'] > 0 else 0, 2),
                'Reddedilen_GÃ¶rÃ¼ntÃ¼': summary['rejected_images_count'],
                'Analiz_Tarihi': summary['analysis_timestamp']
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_csv_path = os.path.join(self.directories['reports'], f'student_routes_summary_{timestamp}.csv')
        summary_df.to_csv(summary_csv_path, index=False, encoding='utf-8-sig')
        
        # 2. DetaylÄ± CSV raporu - Her nokta iÃ§in
        detailed_data = []
        for result in all_results:
            student_code = result['summary']['student_code']
            for point_analysis in result['point_analyses']:
                location_info = point_analysis['location_info']
                for angle, angle_data in point_analysis['angles'].items():
                    detailed_data.append({
                        'Ã–ÄŸrenci_Kodu': student_code,
                        'Nokta_ID': location_info['location_id'],
                        'Koordinat': location_info['coordinates'],
                        'AÃ§Ä±': angle,
                        'GVI_%': round(angle_data.get('gvi', 0), 2),
                        'GÃ¶rÃ¼ntÃ¼_Mevcut': angle_data.get('image_available', False),
                        'Hata': angle_data.get('error', None)
                    })
        
        detailed_df = pd.DataFrame(detailed_data)
        detailed_csv_path = os.path.join(self.directories['reports'], f'student_routes_detailed_{timestamp}.csv')
        detailed_df.to_csv(detailed_csv_path, index=False, encoding='utf-8-sig')
        
        # 3. GÃ¶rselleÅŸtirme raporu
        self.create_route_visualization(all_results, timestamp)
        
        self.logger.info(f"ğŸ“Š Raporlar oluÅŸturuldu:")
        self.logger.info(f"   ğŸ“„ Ã–zet rapor: {summary_csv_path}")
        self.logger.info(f"   ğŸ“„ DetaylÄ± rapor: {detailed_csv_path}")
    
    def create_route_visualization(self, all_results, timestamp):
        """Ã–ÄŸrenci rotalarÄ± iÃ§in gÃ¶rselleÅŸtirme oluÅŸtur"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Ã–ÄŸrenci Okul RotalarÄ± - YeÅŸil Alan Maruziyeti Analizi', fontsize=16, fontweight='bold')
        
        # Veri hazÄ±rlama
        student_codes = []
        avg_gvis = []
        route_lengths = []
        valid_points = []
        gvi_per_km = []
        
        for result in all_results:
            summary = result['summary']
            student_codes.append(summary['student_code'])
            avg_gvis.append(summary['average_route_gvi'])
            route_lengths.append(summary['route_length_km'])
            valid_points.append(summary['valid_points'])
            if summary['route_length_km'] > 0:
                gvi_per_km.append(summary['average_route_gvi'] / summary['route_length_km'])
            else:
                gvi_per_km.append(0)
        
        # 1. Ortalama GVI karÅŸÄ±laÅŸtÄ±rmasÄ±
        axes[0, 0].bar(student_codes, avg_gvis, color='green', alpha=0.7)
        axes[0, 0].set_title('Ã–ÄŸrenci RotalarÄ±nda Ortalama GVI (%)')
        axes[0, 0].set_xlabel('Ã–ÄŸrenci Kodu')
        axes[0, 0].set_ylabel('GVI (%)')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # 2. Rota uzunluÄŸu vs GVI
        axes[0, 1].scatter(route_lengths, avg_gvis, s=100, alpha=0.7, color='darkgreen')
        for i, code in enumerate(student_codes):
            axes[0, 1].annotate(code, (route_lengths[i], avg_gvis[i]), 
                               xytext=(5, 5), textcoords='offset points')
        axes[0, 1].set_title('Rota UzunluÄŸu vs Ortalama GVI')
        axes[0, 1].set_xlabel('Rota UzunluÄŸu (km)')
        axes[0, 1].set_ylabel('Ortalama GVI (%)')
        
        # 3. GVI/km karÅŸÄ±laÅŸtÄ±rmasÄ±
        axes[1, 0].bar(student_codes, gvi_per_km, color='forestgreen', alpha=0.7)
        axes[1, 0].set_title('Kilometre BaÅŸÄ±na GVI Maruziyeti')
        axes[1, 0].set_xlabel('Ã–ÄŸrenci Kodu')
        axes[1, 0].set_ylabel('GVI/km')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # 4. GeÃ§erli nokta sayÄ±sÄ±
        axes[1, 1].bar(student_codes, valid_points, color='olive', alpha=0.7)
        axes[1, 1].set_title('BaÅŸarÄ±yla Analiz Edilen Nokta SayÄ±sÄ±')
        axes[1, 1].set_xlabel('Ã–ÄŸrenci Kodu')
        axes[1, 1].set_ylabel('GeÃ§erli Nokta SayÄ±sÄ±')
        axes[1, 1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        viz_path = os.path.join(self.directories['visualizations'], f'student_routes_comparison_{timestamp}.png')
        plt.savefig(viz_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"   ğŸ“Š GÃ¶rselleÅŸtirme: {viz_path}")
        
        # Her Ã¶ÄŸrenci iÃ§in ayrÄ± rota haritasÄ± oluÅŸtur
        self.create_individual_route_maps(all_results, timestamp)
    
    def create_individual_route_maps(self, all_results, timestamp):
        """Her Ã¶ÄŸrenci iÃ§in ayrÄ± rota haritasÄ± oluÅŸtur"""
        for result in all_results:
            student_code = result['summary']['student_code']
            
            # Rota noktalarÄ±nÄ± ve GVI deÄŸerlerini topla
            points = []
            gvi_values = []
            
            for point_analysis in result['point_analyses']:
                if point_analysis['summary']['valid_images'] > 0:
                    avg_gvi = point_analysis['summary']['average_gvi']
                    # KoordinatlarÄ± parse et
                    coords_str = point_analysis['location_info']['coordinates']
                    lat, lng = map(float, coords_str.split(','))
                    
                    points.append((lat, lng))
                    gvi_values.append(avg_gvi)
            
            if points:
                fig, ax = plt.subplots(1, 1, figsize=(12, 8))
                
                # Rota Ã§izgisi
                lats, lngs = zip(*points)
                ax.plot(lngs, lats, 'b-', linewidth=2, alpha=0.7, label='Rota')
                
                # GVI deÄŸerlerine gÃ¶re renkli noktalar
                scatter = ax.scatter(lngs, lats, c=gvi_values, cmap='RdYlGn', 
                                   s=100, alpha=0.8, edgecolors='black', linewidth=1)
                
                # Colorbar
                cbar = plt.colorbar(scatter, ax=ax)
                cbar.set_label('GVI (%)', rotation=270, labelpad=20)
                
                # Nokta numaralarÄ±
                for i, (lat, lng) in enumerate(points):
                    ax.annotate(f'{i+1}', (lng, lat), xytext=(5, 5), 
                               textcoords='offset points', fontsize=8, 
                               bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))
                
                ax.set_title(f'{student_code} - Okul RotasÄ± YeÅŸil Alan Maruziyeti')
                ax.set_xlabel('Boylam (Longitude)')
                ax.set_ylabel('Enlem (Latitude)')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                route_map_path = os.path.join(self.directories['visualizations'], 
                                            f'{student_code}_route_map_{timestamp}.png')
                plt.savefig(route_map_path, dpi=300, bbox_inches='tight')
                plt.close()
                
                self.logger.info(f"   ğŸ—ºï¸ {student_code} rota haritasÄ±: {route_map_path}")


def main():
    """Ana fonksiyon"""
    print("ğŸŒ¿ Hybrid Segmentation System - Ã–ÄŸrenci Rota Analizi")
    print("=" * 60)
    
    # Analiz tipini seÃ§
    print("ğŸ“Š Analiz Tipi SeÃ§in:")
    print("1. Ã–ÄŸrenci rotalarÄ±nÄ± analiz et (Excel dosyasÄ±ndan)")
    print("2. Tekli lokasyon analizi")
    print("3. Batch processing (Classic model)")
    
    analysis_choice = input("SeÃ§iminiz (1/2/3): ").strip()
    
    # Model tipini seÃ§
    model_type = input("Model tipini seÃ§in (segformer/pspnet/psanet): ").lower()
    if model_type not in ['segformer', 'pspnet', 'psanet']:
        print("GeÃ§ersiz model tipi!")
        return
    
    # API key (SegFormer iÃ§in)
    api_key = None
    if model_type == 'segformer':
        api_key = input("Google Street View API key girin: ").strip()
        if not api_key:
            print("API key gerekli!")
            return
    
    # Config path (Classic modeller iÃ§in)
    config_path = None
    if model_type in ['pspnet', 'psanet']:
        config_path = input("Config dosya yolu girin: ").strip()
        if not config_path or not os.path.exists(config_path):
            print("GeÃ§erli config dosyasÄ± gerekli!")
            return
    
    # Sistemi baÅŸlat
    try:
        system = HybridSegmentationSystem(
            model_type=model_type,
            api_key=api_key,
            config_path=config_path
        )
        
        if analysis_choice == "1":
            # Ã–ÄŸrenci rotalarÄ±nÄ± analiz et
            excel_path = input("Excel dosya yolu girin (varsayÄ±lan: coordinates.xlsx): ").strip()
            if not excel_path:
                excel_path = "coordinates.xlsx"
            
            if not os.path.exists(excel_path):
                print(f"âŒ Excel dosyasÄ± bulunamadÄ±: {excel_path}")
                return
            
            print(f"\nğŸ’ Ã–ÄŸrenci rotalarÄ± analiz ediliyor: {excel_path}")
            all_results = system.analyze_all_student_routes(excel_path)
            
            if all_results:
                print(f"\nğŸ‰ {len(all_results)} Ã¶ÄŸrenci rotasÄ± analiz edildi!")
                print("ğŸ“Š Raporlar 'reports' klasÃ¶rÃ¼nde oluÅŸturuldu")
                print("ğŸ“ˆ GÃ¶rselleÅŸtirmeler 'visualizations' klasÃ¶rÃ¼nde oluÅŸturuldu")
            
        elif analysis_choice == "2":
            # Tekli lokasyon analizi
            if model_type == 'segformer':
                LOCATIONS = [
                    {"id": "loc_001", "name": "Test Lokasyonu 1", "coords": "40.7128,-74.0060"},
                    {"id": "loc_002", "name": "Test Lokasyonu 2", "coords": "34.0522,-118.2437"},
                ]
                
                reject_night = input("Gece fotoÄŸraflarÄ±nÄ± reddet? (y/n): ").lower() == 'y'
                
                all_results = []
                for i, location in enumerate(LOCATIONS, 1):
                    print(f"\n[{i}/{len(LOCATIONS)}] Lokasyon analizi baÅŸlatÄ±lÄ±yor...")
                    result = system.analyze_location(location, reject_night=reject_night)
                    all_results.append(result)
                
                # Rapor oluÅŸtur
                system.create_comprehensive_report(all_results)
            
        elif analysis_choice == "3":
            # Classic model modu - batch processing
            if model_type in ['pspnet', 'psanet']:
                chunk_code = int(input("Chunk code girin: "))
                system.process_batch_classic(chunk_code)
            else:
                print("âŒ Batch processing sadece PSPNet/PSANet modelleri iÃ§in kullanÄ±labilir!")
        
        else:
            print("âŒ GeÃ§ersiz seÃ§im!")
            return
        
        print("\nğŸ‰ Analiz tamamlandÄ±!")
        
    except Exception as e:
        print(f"âŒ Hata: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
